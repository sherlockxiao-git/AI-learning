{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacon\\envs\\tf-1.x\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anacon\\envs\\tf-1.x\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anacon\\envs\\tf-1.x\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anacon\\envs\\tf-1.x\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anacon\\envs\\tf-1.x\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anacon\\envs\\tf-1.x\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_data(data_):\n",
    "    result=[]\n",
    "    for i in range(len(data_)):\n",
    "        img_data = list(map(float,data_.iloc[i,1].split()))\n",
    "        result.append(img_data)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['Usage']==\"Training\"]\n",
    "val_data = data[data['Usage']==\"PublicTest\"]\n",
    "test_data = data[data['Usage']==\"PrivateTest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = translate_data(train_data)\n",
    "X_val = translate_data(val_data)\n",
    "X_test = translate_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['emotion'].values\n",
    "y_val = val_data['emotion'].values\n",
    "y_test = test_data['emotion'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(7,dtype=np.float32)[y_train]\n",
    "y_val = np.eye(7,dtype=np.float32)[y_val]\n",
    "y_test = np.eye(7,dtype=np.float32)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3492, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_batch = 0\n",
    "m_train = X_train.shape[0]#28283\n",
    "index_data = np.arange(m_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size):\n",
    "    global m_train,index_batch\n",
    "    global X_train,y_train\n",
    "    \n",
    "    if index_batch == 0:\n",
    "        np.random.shuffle(index_data)\n",
    "        X_train = X_train[index_data]\n",
    "        y_train = y_train[index_data]\n",
    "    \n",
    "    index_batch_end = index_batch+batch_size\n",
    "    if index_batch_end > m_train:\n",
    "        index_batch_end = m_train\n",
    "    \n",
    "    batch_x = X_train[index_batch:index_batch_end]\n",
    "    batch_y = y_train[index_batch:index_batch_end]\n",
    "    \n",
    "    index_batch = index_batch_end%m_train\n",
    "    \n",
    "    return batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入图像的长*宽*通道数\n",
    "n_width = 48\n",
    "n_height = 48\n",
    "n_channel = 1\n",
    "#输入图像数据大小\n",
    "n_input = n_width*n_height*n_channel\n",
    "#输出类别数\n",
    "n_class = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#其他超参\n",
    "num_epoch = 100\n",
    "batch_size = 100\n",
    "num_batches = int(train_data.shape[0]/batch_size)\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=(None,n_input),name='x')\n",
    "x_ = tf.reshape(x,shape=[-1,n_height,n_width,n_channel])\n",
    "y = tf.placeholder(tf.float32,shape=(None,n_class),name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anacon\\envs\\tf-1.x\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Layer1\n",
    "#input:batch*48*48*3\n",
    "#filter:3*3*1*16\n",
    "#conv_1: 48*48*16\n",
    "#pool:24*24*16\n",
    "w_1 = tf.Variable(tf.random_normal([3,3,n_channel,16]),dtype=tf.float32,name='w_1')\n",
    "b_1 = tf.Variable(tf.random_normal([16]),dtype=tf.float32,name='b_1')\n",
    "conv_1 = tf.nn.conv2d(x_,w_1,strides=[1,1,1,1],padding='SAME')+b_1\n",
    "a_1 = tf.nn.relu(conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_1 = tf.nn.max_pool(a_1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer2\n",
    "#input:24*24*16\n",
    "#filter:3*3*16*32\n",
    "#conv_1: 24*24*32\n",
    "#pool:12*12*32\n",
    "w_2 = tf.Variable(tf.random_normal([3,3,16,32]),dtype=tf.float32,name='w_2')\n",
    "b_2 = tf.Variable(tf.random_normal([32]),dtype=tf.float32,name='b_2')\n",
    "conv_2 = tf.nn.conv2d(pool_1,w_2,strides=[1,1,1,1],padding='SAME')+b_2\n",
    "a_2 = tf.nn.relu(conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_2 = tf.nn.max_pool(a_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer3\n",
    "#input:7*7*32\n",
    "#outpur:120\n",
    "w_3 = tf.Variable(tf.random_normal([12*12*32,120]),dtype=tf.float32,name='w_3')\n",
    "b_3 = tf.Variable(tf.random_normal([120]),dtype=tf.float32,name='b_3')\n",
    "z_3 = tf.matmul(tf.reshape(pool_2,[-1,12*12*32]),w_3)+b_3\n",
    "a_3 = tf.nn.relu(z_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer4\n",
    "#input:120\n",
    "#outpur:84\n",
    "w_4 = tf.Variable(tf.random_normal([120,84]),dtype=tf.float32,name='w_4')\n",
    "b_4 = tf.Variable(tf.random_normal([84]),dtype=tf.float32,name='b_4')\n",
    "z_4 = tf.matmul(a_3,w_4)+b_4\n",
    "a_4 = tf.nn.relu(z_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer5\n",
    "#input:84\n",
    "#outpur:10\n",
    "w_5 = tf.Variable(tf.random_normal([84,n_class]),dtype=tf.float32,name='w_5')\n",
    "b_5 = tf.Variable(tf.random_normal([n_class]),dtype=tf.float32,name='b_5')\n",
    "z_5 = tf.matmul(a_4,w_5)+b_5\n",
    "y_hat = tf.nn.softmax(z_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=z_5,labels=y)\n",
    "cost = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_hat,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>Epoch: 0000, Val acc: 0.189334\n",
      ">>>>>>Epoch: 0001, Val acc: 0.211343\n",
      ">>>>>>Epoch: 0002, Val acc: 0.214729\n",
      ">>>>>>Epoch: 0003, Val acc: 0.224323\n",
      ">>>>>>Epoch: 0004, Val acc: 0.206546\n",
      ">>>>>>Epoch: 0005, Val acc: 0.175508\n",
      ">>>>>>Epoch: 0006, Val acc: 0.234481\n",
      ">>>>>>Epoch: 0007, Val acc: 0.156603\n",
      ">>>>>>Epoch: 0008, Val acc: 0.233634\n",
      ">>>>>>Epoch: 0009, Val acc: 0.248307\n",
      ">>>>>>Epoch: 0010, Val acc: 0.183409\n",
      ">>>>>>Epoch: 0011, Val acc: 0.155192\n",
      ">>>>>>Epoch: 0012, Val acc: 0.127540\n",
      ">>>>>>Epoch: 0013, Val acc: 0.192438\n",
      ">>>>>>Epoch: 0014, Val acc: 0.229684\n",
      ">>>>>>Epoch: 0015, Val acc: 0.134029\n",
      ">>>>>>Epoch: 0016, Val acc: 0.244921\n",
      ">>>>>>Epoch: 0017, Val acc: 0.215576\n",
      ">>>>>>Epoch: 0018, Val acc: 0.249718\n",
      ">>>>>>Epoch: 0019, Val acc: 0.161964\n",
      ">>>>>>Epoch: 0020, Val acc: 0.142212\n",
      ">>>>>>Epoch: 0021, Val acc: 0.140801\n",
      ">>>>>>Epoch: 0022, Val acc: 0.202596\n",
      ">>>>>>Epoch: 0023, Val acc: 0.153781\n",
      ">>>>>>Epoch: 0024, Val acc: 0.200339\n",
      ">>>>>>Epoch: 0025, Val acc: 0.244921\n",
      ">>>>>>Epoch: 0026, Val acc: 0.172122\n",
      ">>>>>>Epoch: 0027, Val acc: 0.166761\n",
      ">>>>>>Epoch: 0028, Val acc: 0.194413\n",
      ">>>>>>Epoch: 0029, Val acc: 0.255361\n",
      ">>>>>>Epoch: 0030, Val acc: 0.177483\n",
      ">>>>>>Epoch: 0031, Val acc: 0.253668\n",
      ">>>>>>Epoch: 0032, Val acc: 0.233634\n",
      ">>>>>>Epoch: 0033, Val acc: 0.251693\n",
      ">>>>>>Epoch: 0034, Val acc: 0.195260\n",
      ">>>>>>Epoch: 0035, Val acc: 0.205135\n",
      ">>>>>>Epoch: 0036, Val acc: 0.253386\n",
      ">>>>>>Epoch: 0037, Val acc: 0.164786\n",
      ">>>>>>Epoch: 0038, Val acc: 0.213036\n",
      ">>>>>>Epoch: 0039, Val acc: 0.236174\n",
      ">>>>>>Epoch: 0040, Val acc: 0.251975\n",
      ">>>>>>Epoch: 0041, Val acc: 0.249718\n",
      ">>>>>>Epoch: 0042, Val acc: 0.262415\n",
      ">>>>>>Epoch: 0043, Val acc: 0.201185\n",
      ">>>>>>Epoch: 0044, Val acc: 0.174379\n",
      ">>>>>>Epoch: 0045, Val acc: 0.255643\n",
      ">>>>>>Epoch: 0046, Val acc: 0.264108\n",
      ">>>>>>Epoch: 0047, Val acc: 0.260440\n",
      ">>>>>>Epoch: 0048, Val acc: 0.251129\n",
      ">>>>>>Epoch: 0049, Val acc: 0.222065\n",
      ">>>>>>Epoch: 0050, Val acc: 0.274831\n",
      ">>>>>>Epoch: 0051, Val acc: 0.229966\n",
      ">>>>>>Epoch: 0052, Val acc: 0.255361\n",
      ">>>>>>Epoch: 0053, Val acc: 0.256208\n",
      ">>>>>>Epoch: 0054, Val acc: 0.279063\n",
      ">>>>>>Epoch: 0055, Val acc: 0.275113\n",
      ">>>>>>Epoch: 0056, Val acc: 0.275677\n",
      ">>>>>>Epoch: 0057, Val acc: 0.267494\n",
      ">>>>>>Epoch: 0058, Val acc: 0.287528\n",
      ">>>>>>Epoch: 0059, Val acc: 0.253950\n",
      ">>>>>>Epoch: 0060, Val acc: 0.289503\n",
      ">>>>>>Epoch: 0061, Val acc: 0.268341\n",
      ">>>>>>Epoch: 0062, Val acc: 0.266648\n",
      ">>>>>>Epoch: 0063, Val acc: 0.290632\n",
      ">>>>>>Epoch: 0064, Val acc: 0.292043\n",
      ">>>>>>Epoch: 0065, Val acc: 0.289503\n",
      ">>>>>>Epoch: 0066, Val acc: 0.268059\n",
      ">>>>>>Epoch: 0067, Val acc: 0.281603\n",
      ">>>>>>Epoch: 0068, Val acc: 0.284424\n",
      ">>>>>>Epoch: 0069, Val acc: 0.291479\n",
      ">>>>>>Epoch: 0070, Val acc: 0.284424\n",
      ">>>>>>Epoch: 0071, Val acc: 0.268905\n",
      ">>>>>>Epoch: 0072, Val acc: 0.292043\n",
      ">>>>>>Epoch: 0073, Val acc: 0.289786\n",
      ">>>>>>Epoch: 0074, Val acc: 0.291196\n",
      ">>>>>>Epoch: 0075, Val acc: 0.239842\n",
      ">>>>>>Epoch: 0076, Val acc: 0.297404\n",
      ">>>>>>Epoch: 0077, Val acc: 0.292325\n",
      ">>>>>>Epoch: 0078, Val acc: 0.293172\n",
      ">>>>>>Epoch: 0079, Val acc: 0.286964\n",
      ">>>>>>Epoch: 0080, Val acc: 0.254515\n",
      ">>>>>>Epoch: 0081, Val acc: 0.286117\n",
      ">>>>>>Epoch: 0082, Val acc: 0.287810\n",
      ">>>>>>Epoch: 0083, Val acc: 0.281321\n",
      ">>>>>>Epoch: 0084, Val acc: 0.299661\n",
      ">>>>>>Epoch: 0085, Val acc: 0.287246\n",
      ">>>>>>Epoch: 0086, Val acc: 0.290914\n",
      ">>>>>>Epoch: 0087, Val acc: 0.302483\n",
      ">>>>>>Epoch: 0088, Val acc: 0.291196\n",
      ">>>>>>Epoch: 0089, Val acc: 0.292889\n",
      ">>>>>>Epoch: 0090, Val acc: 0.286964\n",
      ">>>>>>Epoch: 0091, Val acc: 0.291761\n",
      ">>>>>>Epoch: 0092, Val acc: 0.291761\n",
      ">>>>>>Epoch: 0093, Val acc: 0.299097\n",
      ">>>>>>Epoch: 0094, Val acc: 0.273420\n",
      ">>>>>>Epoch: 0095, Val acc: 0.296275\n",
      ">>>>>>Epoch: 0096, Val acc: 0.304458\n",
      ">>>>>>Epoch: 0097, Val acc: 0.303612\n",
      ">>>>>>Epoch: 0098, Val acc: 0.292889\n",
      ">>>>>>Epoch: 0099, Val acc: 0.303894\n",
      "Model Trained.\n",
      "Accuracy: 0.27978235\n"
     ]
    }
   ],
   "source": [
    "cost_epoches = []\n",
    "val_acc = []\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for epoch in range(num_epoch):\n",
    "        for batch in range(num_batches):\n",
    "            if batch%100==0:\n",
    "                print(\">>\",end='')\n",
    "            batch_x,batch_y = next_batch(batch_size)\n",
    "            tfs.run(optimizer,feed_dict={x:batch_x,y:batch_y})\n",
    "            cost_val = tfs.run(cost,feed_dict={x:batch_x,y:batch_y})\n",
    "            cost_epoches.append(cost_val)   \n",
    "        \n",
    "        result = tfs.run(acc,feed_dict={x:X_val,y:y_val})\n",
    "        val_acc.append(result)\n",
    "        print(\"Epoch: {0:04d}, Val acc: {1:0.6f}\".format(epoch,result))\n",
    "    print(\"Model Trained.\")\n",
    "        \n",
    "    test_acc = tfs.run(acc,feed_dict={x:X_test,y:y_test})\n",
    "    print(\"Accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_epoches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([10,20,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((1,25,25,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.convert_to_tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.nn.max_pool(b,(1,2,2,1),(1,2,2,1),padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as tfs:\n",
    "    d = tfs.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-1.x",
   "language": "python",
   "name": "tf-1.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
